#!/usr/bin/env python3
"""
ğŸ“Š å¸å®‰æ•°æ®ä¸‹è½½å™¨
ä»å¸å®‰å®˜æ–¹æ•°æ®ç½‘ç«™ä¸‹è½½çœŸå®çš„Kçº¿æ•°æ®ç”¨äºæ·±åº¦å­¦ä¹ è®­ç»ƒ

æ”¯æŒåŠŸèƒ½ï¼š
- è‡ªåŠ¨ä¸‹è½½æŒ‡å®šæ—¶é—´èŒƒå›´çš„1åˆ†é’ŸKçº¿æ•°æ®
- æ•°æ®æ¸…æ´—å’Œæ ¼å¼è½¬æ¢
- åˆå¹¶å¤šä¸ªæœˆä»½æ•°æ®
- æ•°æ®è´¨é‡æ£€æŸ¥
"""

import os
import time
import zipfile
from datetime import datetime, timedelta
from typing import List, Optional

import pandas as pd
import requests
from tqdm import tqdm


class BinanceDataDownloader:
    """å¸å®‰æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self, symbol: str = "USDCUSDT", interval: str = "1m"):
        self.symbol = symbol
        self.interval = interval
        self.base_url = "https://data.binance.vision/data/spot/monthly/klines"
        self.data_dir = "data/raw/binance"
        self.processed_dir = "data/processed"
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.processed_dir, exist_ok=True)
        
        print("ğŸ“Š å¸å®‰æ•°æ®ä¸‹è½½å™¨åˆå§‹åŒ–")
        print(f"äº¤æ˜“å¯¹: {self.symbol}")
        print(f"æ—¶é—´é—´éš”: {self.interval}")
        print(f"æ•°æ®ç›®å½•: {self.data_dir}")
    
    def generate_download_urls(self, start_year: int, start_month: int, 
                               end_year: int, end_month: int) -> List[str]:
        """ç”Ÿæˆä¸‹è½½é“¾æ¥åˆ—è¡¨ï¼Œé¿å…æœªæ¥æ—¥æœŸ"""
        urls = []
        
        current_date = datetime(start_year, start_month, 1)
        end_date = datetime(end_year, end_month, 1)
        
        # ç¡®ä¿ä¸ä¼šä¸‹è½½æœªæ¥çš„æ•°æ®
        now = datetime.now()
        max_date = datetime(now.year, now.month, 1)
        if end_date > max_date:
            end_date = max_date
            print(f"âš ï¸  è°ƒæ•´ç»“æŸæ—¥æœŸåˆ°å½“å‰æœˆä»½: {max_date.strftime('%Y-%m')}")
        
        while current_date <= end_date:
            year = current_date.year
            month = current_date.month
            
            # æ„å»ºæ–‡ä»¶åå’ŒURL
            filename = f"{self.symbol}-{self.interval}-{year}-{month:02d}.zip"
            url = f"{self.base_url}/{self.symbol}/{self.interval}/{filename}"
            urls.append(url)
            
            # ä¸‹ä¸ªæœˆ
            if month == 12:
                current_date = datetime(year + 1, 1, 1)
            else:
                current_date = datetime(year, month + 1, 1)
        
        return urls
    
    def download_file(self, url: str, save_path: str) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        try:
            print(f"ğŸ“¥ ä¸‹è½½: {os.path.basename(url)}")
            
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            
            with open(save_path, 'wb') as f, tqdm(
                desc=os.path.basename(save_path),
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")
            return True
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {url}")
            print(f"é”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def extract_zip(self, zip_path: str) -> Optional[str]:
        """è§£å‹ZIPæ–‡ä»¶"""
        try:
            extract_dir = os.path.dirname(zip_path)
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                if len(file_list) == 1:
                    csv_filename = file_list[0]
                    zip_ref.extractall(extract_dir)
                    csv_path = os.path.join(extract_dir, csv_filename)
                    
                    print(f"ğŸ“‚ è§£å‹å®Œæˆ: {csv_filename}")
                    
                    # åˆ é™¤ZIPæ–‡ä»¶èŠ‚çœç©ºé—´
                    os.remove(zip_path)
                    
                    return csv_path
                else:
                    print(f"âš ï¸  ZIPæ–‡ä»¶åŒ…å«å¤šä¸ªæ–‡ä»¶: {file_list}")
                    return None
                    
        except zipfile.BadZipFile:
            print(f"âŒ æŸåçš„ZIPæ–‡ä»¶: {zip_path}")
            return None
        except Exception as e:
            print(f"âŒ è§£å‹å¤±è´¥: {e}")
            return None
    
    def process_csv(self, csv_path: str) -> pd.DataFrame:
        """å¤„ç†å•ä¸ªCSVæ–‡ä»¶ï¼Œå¢å¼ºæ—¶é—´æˆ³å¤„ç†"""
        try:
            # å¸å®‰æ•°æ®åˆ—å
            columns = [
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume',
                'ignore'
            ]
            
            # è¯»å–æ•°æ®
            print(f"ğŸ“– è¯»å–CSVæ–‡ä»¶: {os.path.basename(csv_path)}")
            df = pd.read_csv(csv_path, names=columns)
            print(f"ğŸ“Š åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
            
            # æ™ºèƒ½æ£€æµ‹æ—¶é—´æˆ³æ ¼å¼å¹¶å¤„ç†
            try:
                ts_sample = df['timestamp'].iloc[:10]
                print(f"ğŸ•’ æ—¶é—´æˆ³æ ·æœ¬: {ts_sample.tolist()}")
                
                # æ£€æµ‹æ—¶é—´æˆ³ä½æ•°
                first_ts = int(df['timestamp'].iloc[0])
                ts_str = str(first_ts)
                ts_digits = len(ts_str)
                
                print(f"ğŸ” æ—¶é—´æˆ³ä½æ•°: {ts_digits}")
                
                if ts_digits == 13:
                    # æ ‡å‡†æ¯«ç§’æ—¶é—´æˆ³
                    print("âœ… æ£€æµ‹åˆ°æ¯«ç§’æ—¶é—´æˆ³æ ¼å¼")
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                elif ts_digits == 16:
                    # å¾®ç§’æ—¶é—´æˆ³ï¼ˆéœ€è¦é™¤ä»¥1000è½¬æ¢ä¸ºæ¯«ç§’ï¼‰
                    print("âœ… æ£€æµ‹åˆ°å¾®ç§’æ—¶é—´æˆ³æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ¯«ç§’")
                    df['timestamp'] = pd.to_datetime(df['timestamp'] / 1000, unit='ms')
                elif ts_digits == 10:
                    # ç§’æ—¶é—´æˆ³
                    print("âœ… æ£€æµ‹åˆ°ç§’æ—¶é—´æˆ³æ ¼å¼")
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                else:
                    # å°è¯•è‡ªåŠ¨æ£€æµ‹
                    print(f"âš ï¸  æœªçŸ¥æ—¶é—´æˆ³æ ¼å¼({ts_digits}ä½)ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹...")
                    
                    # å°è¯•ä¸åŒçš„å•ä½
                    for unit in ['ms', 's']:
                        try:
                            test_ts = pd.to_datetime(df['timestamp'].iloc[0], unit=unit)
                            # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†æ—¶é—´èŒƒå›´å†… (2010-2030)
                            if datetime(2010, 1, 1) <= test_ts <= datetime(2030, 1, 1):
                                print(f"âœ… è‡ªåŠ¨æ£€æµ‹æˆåŠŸï¼Œä½¿ç”¨{unit}å•ä½")
                                df['timestamp'] = pd.to_datetime(df['timestamp'], unit=unit)
                                break
                        except:
                            continue
                    else:
                        raise ValueError(f"æ— æ³•è§£ææ—¶é—´æˆ³æ ¼å¼: {ts_digits}ä½")
                
                # éªŒè¯è½¬æ¢åçš„æ—¶é—´æˆ³
                min_time = df['timestamp'].min()
                max_time = df['timestamp'].max()
                print(f"ğŸ“… æ—¶é—´èŒƒå›´: {min_time} åˆ° {max_time}")
                
                # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦åˆç† (2010-2030å¹´)
                if min_time < datetime(2010, 1, 1) or max_time > datetime(2030, 1, 1):
                    raise ValueError(f"æ—¶é—´èŒƒå›´å¼‚å¸¸: {min_time} - {max_time}")
                
                print("âœ… æ—¶é—´æˆ³è½¬æ¢æˆåŠŸ")
                
            except Exception as e:
                print(f"âŒ æ—¶é—´æˆ³å¤„ç†å¤±è´¥: {e}")
                os.remove(csv_path)
                return pd.DataFrame()
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            processed_df = df[['timestamp', 'open', 'high', 'low', 'close',
                              'volume']].copy()
            
            # æ•°æ®ç±»å‹è½¬æ¢
            for col in ['open', 'high', 'low', 'close', 'volume']:
                processed_df[col] = pd.to_numeric(processed_df[col],
                                                  errors='coerce')
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            null_count = processed_df.isnull().sum().sum()
            if null_count > 0:
                print(f"âš ï¸  å‘ç° {null_count} ä¸ªç¼ºå¤±å€¼ï¼Œå°†è¿›è¡Œæ¸…ç†")
                processed_df = processed_df.dropna()
            
            # æ£€æŸ¥ä»·æ ¼åˆç†æ€§
            price_cols = ['open', 'high', 'low', 'close']
            for col in price_cols:
                if (processed_df[col] <= 0).any():
                    print("âš ï¸  å‘ç°éæ­£ä»·æ ¼ï¼Œå°†è¿›è¡Œæ¸…ç†")
                    processed_df = processed_df[processed_df[col] > 0]
            
            # æ£€æŸ¥OHLCé€»è¾‘
            invalid_ohlc = (
                (processed_df['high'] < processed_df['low']) |
                (processed_df['high'] < processed_df['open']) |
                (processed_df['high'] < processed_df['close']) |
                (processed_df['low'] > processed_df['open']) |
                (processed_df['low'] > processed_df['close'])
            )
            
            if invalid_ohlc.any():
                invalid_count = invalid_ohlc.sum()
                print(f"âš ï¸  å‘ç° {invalid_count} æ¡OHLCé€»è¾‘é”™è¯¯æ•°æ®ï¼Œå°†è¿›è¡Œæ¸…ç†")
                processed_df = processed_df[~invalid_ohlc]
            
            # æŒ‰æ—¶é—´æ’åº
            processed_df = processed_df.sort_values('timestamp').reset_index(
                drop=True)
            
            print(f"ğŸ“Š å¤„ç†å®Œæˆ: {len(processed_df)} æ¡æœ‰æ•ˆæ•°æ®")
            
            # åˆ é™¤åŸå§‹CSVæ–‡ä»¶
            os.remove(csv_path)
            
            return processed_df
            
        except Exception as e:
            print(f"âŒ å¤„ç†CSVå¤±è´¥: {e}")
            # åˆ é™¤å¯èƒ½æŸåçš„æ–‡ä»¶
            if os.path.exists(csv_path):
                os.remove(csv_path)
            return pd.DataFrame()
    
    def download_single_month(self, year: int, month: int) -> str:
        """ä¸‹è½½å•ä¸ªæœˆä»½çš„æ•°æ®å¹¶ä¿å­˜"""
        print(f"\nğŸ“… ä¸‹è½½ {year}-{month:02d} æœˆæ•°æ®")
        print("-" * 40)
        
        # ç”Ÿæˆæ–‡ä»¶åå’Œè·¯å¾„
        filename = f"{self.symbol}-{self.interval}-{year}-{month:02d}.zip"
        url = f"{self.base_url}/{self.symbol}/{self.interval}/{filename}"
        zip_path = os.path.join(self.data_dir, filename)
        
        # æ£€æŸ¥æœˆä»½æ•°æ®æ˜¯å¦å·²å­˜åœ¨
        monthly_csv = os.path.join(self.processed_dir, f"{self.symbol}_{year}_{month:02d}.csv")
        if os.path.exists(monthly_csv):
            print(f"âœ… æœˆä»½æ•°æ®å·²å­˜åœ¨: {monthly_csv}")
            return monthly_csv
        
        # ä¸‹è½½æ–‡ä»¶
        if not self.download_file(url, zip_path):
            print(f"âŒ {year}-{month:02d} ä¸‹è½½å¤±è´¥")
            return ""
        
        # è§£å‹æ–‡ä»¶
        csv_path = self.extract_zip(zip_path)
        if not csv_path:
            print(f"âŒ {year}-{month:02d} è§£å‹å¤±è´¥")
            return ""
        
        # å¤„ç†æ•°æ®
        df = self.process_csv(csv_path)
        if df.empty:
            print(f"âŒ {year}-{month:02d} æ•°æ®å¤„ç†å¤±è´¥")
            return ""
        
        # ä¿å­˜æœˆä»½æ•°æ®
        df.to_csv(monthly_csv, index=False)
        file_size = os.path.getsize(monthly_csv) / 1024 / 1024
        print(f"ğŸ’¾ {year}-{month:02d} å·²ä¿å­˜: {monthly_csv} ({file_size:.2f}MB)")
        
        return monthly_csv
    
    def merge_monthly_files(self, file_paths: List[str], output_filename: str) -> str:
        """åˆå¹¶å¤šä¸ªæœˆä»½æ–‡ä»¶"""
        print(f"\nğŸ”— åˆå¹¶ {len(file_paths)} ä¸ªæœˆä»½æ–‡ä»¶...")
        
        all_data = []
        total_records = 0
        
        for file_path in sorted(file_paths):
            if os.path.exists(file_path):
                df = pd.read_csv(file_path)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                all_data.append(df)
                total_records += len(df)
                month_name = os.path.basename(file_path).replace('.csv', '')
                print(f"  ğŸ“‚ {month_name}: {len(df):,} æ¡è®°å½•")
        
        if not all_data:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœˆä»½æ•°æ®")
            return ""
        
        # åˆå¹¶æ•°æ®
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # æŒ‰æ—¶é—´æ’åº
        combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)
        
        # å»é‡
        before_dedup = len(combined_df)
        combined_df = combined_df.drop_duplicates(subset=['timestamp']).reset_index(drop=True)
        after_dedup = len(combined_df)
        
        if before_dedup != after_dedup:
            removed_count = before_dedup - after_dedup
            print(f"ğŸ§¹ å»é‡: åˆ é™¤äº† {removed_count} æ¡é‡å¤æ•°æ®")
        
        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        output_path = os.path.join(self.processed_dir, output_filename)
        combined_df.to_csv(output_path, index=False)
        
        # ç»Ÿè®¡ä¿¡æ¯
        file_size = os.path.getsize(output_path) / 1024 / 1024
        time_span = (combined_df['timestamp'].max() - combined_df['timestamp'].min()).days
        
        print(f"\nâœ… åˆå¹¶å®Œæˆ!")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(combined_df):,}")
        print(f"ğŸ“… æ—¶é—´è·¨åº¦: {time_span} å¤©")
        print(f"ğŸ•’ æ—¶é—´èŒƒå›´: {combined_df['timestamp'].min()} åˆ° {combined_df['timestamp'].max()}")
        
        return output_path

    def download_month_range(self, start_year: int, start_month: int,
                           end_year: int, end_month: int) -> List[str]:
        """ä¸‹è½½æŒ‡å®šæœˆä»½èŒƒå›´çš„æ•°æ®ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
        print(f"\nğŸš€ åˆ†æœˆä¸‹è½½ç­–ç•¥: {start_year}-{start_month:02d} åˆ° {end_year}-{end_month:02d}")
        print("=" * 60)
        
        # ç”Ÿæˆæœˆä»½åˆ—è¡¨
        months = []
        current_date = datetime(start_year, start_month, 1)
        end_date = datetime(end_year, end_month, 1)
        
        # ç¡®ä¿ä¸ä¼šä¸‹è½½æœªæ¥çš„æ•°æ®
        now = datetime.now()
        max_date = datetime(now.year, now.month, 1)
        if end_date > max_date:
            end_date = max_date
            print(f"âš ï¸  è°ƒæ•´ç»“æŸæ—¥æœŸåˆ°å½“å‰æœˆä»½: {max_date.strftime('%Y-%m')}")
        
        while current_date <= end_date:
            months.append((current_date.year, current_date.month))
            # ä¸‹ä¸ªæœˆ
            if current_date.month == 12:
                current_date = datetime(current_date.year + 1, 1, 1)
            else:
                current_date = datetime(current_date.year, current_date.month + 1, 1)
        
        print(f"ğŸ“‹ éœ€è¦ä¸‹è½½çš„æœˆä»½: {[f'{y}-{m:02d}' for y, m in months]}")
        
        # åˆ†æœˆä¸‹è½½
        successful_files = []
        failed_months = []
        
        for i, (year, month) in enumerate(months, 1):
            print(f"\nè¿›åº¦: {i}/{len(months)}")
            
            try:
                monthly_file = self.download_single_month(year, month)
                if monthly_file:
                    successful_files.append(monthly_file)
                    print(f"âœ… {year}-{month:02d} ä¸‹è½½æˆåŠŸ")
                else:
                    failed_months.append(f"{year}-{month:02d}")
                    print(f"âŒ {year}-{month:02d} ä¸‹è½½å¤±è´¥")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                if i < len(months):  # æœ€åä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿ
                    time.sleep(1)
                    
            except Exception as e:
                failed_months.append(f"{year}-{month:02d}")
                print(f"âŒ {year}-{month:02d} ä¸‹è½½å¼‚å¸¸: {e}")
        
        # ä¸‹è½½æ±‡æ€»
        print(f"\nğŸ“Š ä¸‹è½½æ±‡æ€»:")
        print(f"âœ… æˆåŠŸ: {len(successful_files)}/{len(months)} ä¸ªæœˆä»½")
        print(f"âŒ å¤±è´¥: {len(failed_months)}/{len(months)} ä¸ªæœˆä»½")
        
        if failed_months:
            print(f"âŒ å¤±è´¥æœˆä»½: {failed_months}")
            print("ğŸ’¡ å¯ä»¥ç¨åé‡æ–°è¿è¡Œç¨‹åºï¼Œåªä¸‹è½½å¤±è´¥çš„æœˆä»½")
        
        return successful_files

    def quick_download_recent(self, months: int = 6) -> str:
        """æ™ºèƒ½ä¸‹è½½æœ€è¿‘å‡ ä¸ªæœˆçš„æ•°æ®ï¼Œè‡ªåŠ¨æ£€æŸ¥æœ¬åœ°æ–‡ä»¶"""
        print(f"ğŸš€ æ™ºèƒ½ä¸‹è½½æœ€è¿‘ {months} ä¸ªæœˆçš„å†å²æ•°æ®")
        
        # è®¡ç®—éœ€è¦çš„æœˆä»½èŒƒå›´
        end_date = datetime.now() - timedelta(days=30)
        start_date = end_date - timedelta(days=months * 30)
        
        print(f"ğŸ“… ç›®æ ‡æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m')} åˆ° {end_date.strftime('%Y-%m')}")
        
        # ç”Ÿæˆéœ€è¦çš„æœˆä»½åˆ—è¡¨
        required_months = []
        current_date = datetime(start_date.year, start_date.month, 1)
        end_check = datetime(end_date.year, end_date.month, 1)
        
        # ç¡®ä¿ä¸è¶…è¿‡å½“å‰æ—¶é—´
        now = datetime.now()
        max_date = datetime(now.year, now.month, 1)
        if end_check > max_date:
            end_check = max_date
        
        while current_date <= end_check:
            required_months.append((current_date.year, current_date.month))
            if current_date.month == 12:
                current_date = datetime(current_date.year + 1, 1, 1)
            else:
                current_date = datetime(current_date.year, current_date.month + 1, 1)
        
        print(f"ğŸ“‹ éœ€è¦çš„æœˆä»½: {[f'{y}-{m:02d}' for y, m in required_months]}")
        
        # æ£€æŸ¥æœ¬åœ°å·²æœ‰æ–‡ä»¶å’Œéœ€è¦ä¸‹è½½çš„æ–‡ä»¶
        existing_files = []
        missing_months = []
        
        for year, month in required_months:
            monthly_csv = os.path.join(self.processed_dir, f"{self.symbol}_{year}_{month:02d}.csv")
            if os.path.exists(monthly_csv):
                existing_files.append(monthly_csv)
                print(f"âœ… æœ¬åœ°å·²å­˜åœ¨: {year}-{month:02d}")
            else:
                missing_months.append((year, month))
                print(f"ğŸ” éœ€è¦ä¸‹è½½: {year}-{month:02d}")
        
        # ä¸‹è½½ç¼ºå¤±çš„æœˆä»½
        if missing_months:
            print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½ {len(missing_months)} ä¸ªç¼ºå¤±æœˆä»½...")
            download_success = 0
            
            for year, month in missing_months:
                try:
                    monthly_file = self.download_single_month(year, month)
                    if monthly_file:
                        existing_files.append(monthly_file)
                        download_success += 1
                        print(f"âœ… {year}-{month:02d} ä¸‹è½½æˆåŠŸ")
                    else:
                        print(f"âŒ {year}-{month:02d} ä¸‹è½½å¤±è´¥")
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                    time.sleep(1)
                except Exception as e:
                    print(f"âŒ {year}-{month:02d} ä¸‹è½½å¼‚å¸¸: {e}")
            
            print(f"\nğŸ“Š ä¸‹è½½ç»“æœ: {download_success}/{len(missing_months)} ä¸ªæœˆä»½æˆåŠŸ")
        else:
            print("âœ… æ‰€æœ‰éœ€è¦çš„æœˆä»½æ–‡ä»¶éƒ½å·²å­˜åœ¨æœ¬åœ°")
        
        # æ£€æŸ¥æ˜¯å¦è·å¾—äº†æ‰€æœ‰éœ€è¦çš„æ–‡ä»¶
        if len(existing_files) < len(required_months):
            missing_count = len(required_months) - len(existing_files)
            print(f"âš ï¸  ä»æœ‰ {missing_count} ä¸ªæœˆä»½ç¼ºå¤±ï¼Œå°†ä½¿ç”¨å·²æœ‰çš„ {len(existing_files)} ä¸ªæœˆä»½æ•°æ®")
        
        if not existing_files:
            print("âŒ æ²¡æœ‰ä»»ä½•å¯ç”¨çš„æœˆä»½æ•°æ®")
            return ""
        
        # è‡ªåŠ¨åˆå¹¶æ‰€æœ‰å¯ç”¨çš„æœˆä»½æ•°æ®
        print(f"\nğŸ”— è‡ªåŠ¨åˆå¹¶ {len(existing_files)} ä¸ªæœˆä»½æ–‡ä»¶...")
        output_filename = f"{self.symbol}_recent_{months}months.csv"
        merged_file = self.merge_monthly_files(existing_files, output_filename)
        
        if merged_file:
            print(f"\nğŸ‰ å®Œæˆï¼æœ€ç»ˆæ•°æ®æ–‡ä»¶: {merged_file}")
            if len(existing_files) == len(required_months):
                print("âœ… æ‰€æœ‰æœˆä»½æ•°æ®å®Œæ•´")
            else:
                print(f"âš ï¸  ä½¿ç”¨äº† {len(existing_files)}/{len(required_months)} ä¸ªæœˆä»½çš„æ•°æ®")
        
        return merged_file


def main():
    """ä¸»å‡½æ•° - æä¾›å‡ ç§ä½¿ç”¨æ–¹å¼"""
    print("ğŸ“Š å¸å®‰æ•°æ®ä¸‹è½½å™¨ - åˆ†æœˆä¸‹è½½ç­–ç•¥")
    print("=" * 50)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = BinanceDataDownloader("USDCUSDT", "1m")
    
    # æ£€æŸ¥å·²å­˜åœ¨çš„æœˆä»½æ–‡ä»¶
    existing_files = []
    processed_dir = downloader.processed_dir
    if os.path.exists(processed_dir):
        for file in os.listdir(processed_dir):
            if file.startswith("USDCUSDT_") and file.endswith(".csv") and "_recent_" not in file:
                existing_files.append(file)
    
    if existing_files:
        print(f"\nğŸ“‚ å‘ç°å·²å­˜åœ¨çš„æœˆä»½æ•°æ®æ–‡ä»¶ï¼š")
        for file in sorted(existing_files):
            file_path = os.path.join(processed_dir, file)
            file_size = os.path.getsize(file_path) / 1024 / 1024
            print(f"  ğŸ“„ {file} ({file_size:.2f}MB)")
    
    print("\nè¯·é€‰æ‹©ä¸‹è½½æ–¹å¼:")
    print("1. å¿«é€Ÿä¸‹è½½æœ€è¿‘6ä¸ªæœˆå†å²æ•°æ®ï¼ˆåˆ†æœˆç­–ç•¥ï¼‰")
    print("2. å¿«é€Ÿä¸‹è½½æœ€è¿‘12ä¸ªæœˆå†å²æ•°æ®")
    print("3. è‡ªå®šä¹‰æ—¶é—´èŒƒå›´ä¸‹è½½")
    print("4. é‡æ–°ä¸‹è½½å¤±è´¥çš„æœˆä»½ï¼ˆ4æœˆï¼‰")
    print("5. åˆå¹¶ç°æœ‰æœˆä»½æ–‡ä»¶")
    print("6. æŸ¥çœ‹å·²ä¸‹è½½çš„æœˆä»½çŠ¶æ€")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
        
        if choice == "1":
            # æœ€è¿‘6ä¸ªæœˆå†å²æ•°æ®
            save_path = downloader.quick_download_recent(6)
            if save_path:
                print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼æ•°æ®æ–‡ä»¶: {save_path}")
                print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
                print("åœ¨æ·±åº¦å­¦ä¹ ç¨‹åºä¸­ä¿®æ”¹é…ç½®:")
                print(f"data_file: str = \"{save_path}\"")
            
        elif choice == "2":
            # æœ€è¿‘12ä¸ªæœˆå†å²æ•°æ®
            save_path = downloader.quick_download_recent(12)
            if save_path:
                print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼æ•°æ®æ–‡ä»¶: {save_path}")
        
        elif choice == "3":
            # è‡ªå®šä¹‰èŒƒå›´
            print("\nè¯·è¾“å…¥å¼€å§‹æ—¶é—´:")
            start_year = int(input("å¼€å§‹å¹´ä»½ (å¦‚ 2024): "))
            start_month = int(input("å¼€å§‹æœˆä»½ (1-12): "))
            
            print("\nè¯·è¾“å…¥ç»“æŸæ—¶é—´:")
            end_year = int(input("ç»“æŸå¹´ä»½ (å¦‚ 2025): "))
            end_month = int(input("ç»“æŸæœˆä»½ (1-12): "))
            
            monthly_files = downloader.download_month_range(start_year, start_month, end_year, end_month)
            if monthly_files:
                filename = f"USDCUSDT_{start_year}_{start_month:02d}_to_{end_year}_{end_month:02d}.csv"
                merged_file = downloader.merge_monthly_files(monthly_files, filename)
                if merged_file:
                    print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼æ•°æ®æ–‡ä»¶: {merged_file}")
        
        elif choice == "4":
            # é‡æ–°ä¸‹è½½å¤±è´¥çš„æœˆä»½ï¼ˆç‰¹åˆ«æ˜¯4æœˆï¼‰
            print("\nğŸ”„ é‡æ–°ä¸‹è½½2025å¹´4æœˆæ•°æ®...")
            monthly_file = downloader.download_single_month(2025, 4)
            if monthly_file:
                print(f"âœ… 4æœˆæ•°æ®ä¸‹è½½æˆåŠŸ: {monthly_file}")
                
                # è¯¢é—®æ˜¯å¦é‡æ–°åˆå¹¶6ä¸ªæœˆæ•°æ®
                merge_choice = input("\næ˜¯å¦é‡æ–°åˆå¹¶å®Œæ•´çš„6ä¸ªæœˆæ•°æ®ï¼Ÿ(y/n): ").strip().lower()
                if merge_choice == 'y':
                    # æŸ¥æ‰¾æ‰€æœ‰æœˆä»½æ–‡ä»¶
                    months_files = []
                    for year, month in [(2024, 11), (2024, 12), (2025, 1), (2025, 2), (2025, 3), (2025, 4), (2025, 5)]:
                        file_path = os.path.join(processed_dir, f"USDCUSDT_{year}_{month:02d}.csv")
                        if os.path.exists(file_path):
                            months_files.append(file_path)
                    
                    if len(months_files) >= 6:  # è‡³å°‘6ä¸ªæœˆ
                        merged_file = downloader.merge_monthly_files(months_files, "USDCUSDT_recent_6months.csv")
                        if merged_file:
                            print(f"\nğŸ‰ é‡æ–°åˆå¹¶å®Œæˆï¼æ•°æ®æ–‡ä»¶: {merged_file}")
            else:
                print("âŒ 4æœˆæ•°æ®ä¸‹è½½å¤±è´¥")
        
        elif choice == "5":
            # åˆå¹¶ç°æœ‰æœˆä»½æ–‡ä»¶
            if not existing_files:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯åˆå¹¶çš„æœˆä»½æ–‡ä»¶")
                return
            
            print(f"\nğŸ“‚ æ‰¾åˆ° {len(existing_files)} ä¸ªæœˆä»½æ–‡ä»¶")
            merge_choice = input("æ˜¯å¦åˆå¹¶æ‰€æœ‰æœˆä»½æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
            if merge_choice == 'y':
                file_paths = [os.path.join(processed_dir, f) for f in existing_files]
                merged_file = downloader.merge_monthly_files(file_paths, "USDCUSDT_merged_all.csv")
                if merged_file:
                    print(f"\nğŸ‰ åˆå¹¶å®Œæˆï¼æ•°æ®æ–‡ä»¶: {merged_file}")
        
        elif choice == "6":
            # æŸ¥çœ‹å·²ä¸‹è½½çš„æœˆä»½çŠ¶æ€
            print("\nğŸ“Š å·²ä¸‹è½½æœˆä»½çŠ¶æ€:")
            if not existing_files:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœˆä»½æ•°æ®æ–‡ä»¶")
            else:
                total_size = 0
                total_records = 0
                for file in sorted(existing_files):
                    file_path = os.path.join(processed_dir, file)
                    file_size = os.path.getsize(file_path) / 1024 / 1024
                    total_size += file_size
                    
                    # è¯»å–è®°å½•æ•°
                    try:
                        df = pd.read_csv(file_path)
                        records = len(df)
                        total_records += records
                        print(f"  ğŸ“„ {file}: {records:,} æ¡è®°å½• ({file_size:.2f}MB)")
                    except:
                        print(f"  ğŸ“„ {file}: æ— æ³•è¯»å– ({file_size:.2f}MB)")
                
                print(f"\nğŸ“Š æ±‡æ€»:")
                print(f"  æ€»æ–‡ä»¶æ•°: {len(existing_files)}")
                print(f"  æ€»å¤§å°: {total_size:.2f}MB")
                print(f"  æ€»è®°å½•æ•°: {total_records:,}")
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·å–æ¶ˆä¸‹è½½")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    main() 