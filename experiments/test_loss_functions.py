#!/usr/bin/env python3
"""
ğŸ§ª æŸå¤±å‡½æ•°è‡ªåŠ¨æµ‹è¯•è„šæœ¬
å¿«é€Ÿæµ‹è¯•ä¸åŒæŸå¤±å‡½æ•°çš„æ•ˆæœå¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import Dict, List

import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main import DeepLearningExperiment
from training.config import ExperimentConfig


class LossFunctionTester:
    """æŸå¤±å‡½æ•°æµ‹è¯•å™¨"""
    
    def __init__(self, test_epochs: int = 3):
        self.test_epochs = test_epochs
        self.results = []
        self.start_time = datetime.now()
        
    def test_loss_function(self, loss_type: str, 
                          weight_config: float = None,
                          custom_params: Dict = None) -> Dict:
        """æµ‹è¯•å•ä¸ªæŸå¤±å‡½æ•°"""
        weight_suffix = f"_w{weight_config}" if weight_config else ""
        test_name = f"{loss_type}{weight_suffix}"
        
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•: {test_name}")
        if weight_config:
            print(f"ğŸ“Š å˜åŒ–ç±»æƒé‡: {weight_config}")
        print(f"{'='*60}")
        
        # åˆ›å»ºé…ç½®
        config = ExperimentConfig()
        config.loss_function_type = loss_type
        config.max_epochs = self.test_epochs
        
        # ğŸ¯ åŠ¨æ€è®¾ç½®class_weights
        if weight_config and loss_type == 'binary_cross_entropy':
            config.class_weights = [1.0, weight_config]
            print(f"ğŸ“ˆ ä½¿ç”¨æƒé‡é…ç½®: [1.0, {weight_config}]")
        
        # ğŸ¯ ä¸ºæ¯ä¸ªé…ç½®åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
        base_output_dir = "outputs"  # ç›´æ¥ä½¿ç”¨outputsï¼Œå› ä¸ºæˆ‘ä»¬åœ¨experimentsç›®å½•ä¸‹
        config_output_dir = f"{base_output_dir}/{test_name}"
        
        # æ›´æ–°æ‰€æœ‰è¾“å‡ºè·¯å¾„
        config.output_dir = config_output_dir
        config.model_save_dir = f"{config_output_dir}/models"
        config.log_dir = f"{config_output_dir}/logs"
        config.plot_dir = f"{config_output_dir}/plots"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        os.makedirs(config.model_save_dir, exist_ok=True)
        os.makedirs(config.log_dir, exist_ok=True)
        os.makedirs(config.plot_dir, exist_ok=True)
        
        # è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            for key, value in custom_params.items():
                if key == 'loss_function_params':
                    # æ›´æ–°æŸå¤±å‡½æ•°å‚æ•°
                    for loss_func_name, params in value.items():
                        if loss_func_name in config.loss_function_params:
                            config.loss_function_params[loss_func_name].update(params)
                elif hasattr(config, key):
                    setattr(config, key, value)
        
        # è¿è¡Œå®éªŒ
        start_time = time.time()
        try:
            experiment = DeepLearningExperiment(config)
            results = experiment.run_experiment()
            
            # æå–å…³é”®æŒ‡æ ‡
            key_metrics = self._extract_key_metrics(results, loss_type)
            key_metrics['training_time'] = time.time() - start_time
            key_metrics['status'] = 'success'
            key_metrics['model_save_dir'] = config.model_save_dir  # è®°å½•æ¨¡å‹ä¿å­˜è·¯å¾„
            
            return key_metrics
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return {
                'loss_function': loss_type,
                'status': 'failed',
                'error': str(e),
                'training_time': time.time() - start_time,
                'model_save_dir': config.model_save_dir if 'config' in locals() else None
            }
    
    def _extract_key_metrics(self, results: Dict, 
                           loss_type: str) -> Dict:
        """æå–å…³é”®è¯„ä¼°æŒ‡æ ‡"""
        # å‡è®¾resultsåŒ…å«å„æ—¶é—´å°ºåº¦çš„ç»“æœ
        metrics = {'loss_function': loss_type}
        
        # æå–5åˆ†é’Ÿé¢„æµ‹ç»“æœï¼ˆä¸»è¦å…³æ³¨ï¼‰
        if '5min' in results:
            result_5min = results['5min']
            
            # åŸºç¡€æŒ‡æ ‡
            metrics.update({
                'accuracy': float(result_5min.get('accuracy', 0)),
                'precision': float(result_5min.get('precision', 0)),
                'recall': float(result_5min.get('recall', 0)),
                'f1_score': float(result_5min.get('f1', 0)),
            })
            
            # æ··æ·†çŸ©é˜µ
            cm = result_5min.get('confusion_matrix')
            if cm is not None:
                # è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
                stable_correct = int(cm[0, 0])
                stable_total = int(cm[0, 0] + cm[0, 1])
                change_correct = int(cm[1, 1])
                change_total = int(cm[1, 0] + cm[1, 1])
                
                stable_accuracy = (stable_correct / stable_total 
                                 if stable_total > 0 else 0.0)
                change_accuracy = (change_correct / change_total 
                                 if change_total > 0 else 0.0)
                
                # ğŸ¯ æ–°å¢ï¼šè®¡ç®—ç¾éš¾æ€§é”™è¯¯ç‡
                total_samples = stable_total + change_total
                catastrophic_errors = cm[0, 1] + cm[1, 0]  # äº’ç›¸è¯¯åˆ¤
                catastrophic_rate = (catastrophic_errors / total_samples 
                                   if total_samples > 0 else 0.0)
                
                metrics.update({
                    'stable_accuracy': float(stable_accuracy),
                    'change_accuracy': float(change_accuracy),
                    'false_positives': int(cm[0, 1]),  # ç¨³å®šè¯¯åˆ¤ä¸ºå˜åŒ–
                    'false_negatives': int(cm[1, 0]),  # å˜åŒ–è¯¯åˆ¤ä¸ºç¨³å®š
                    'catastrophic_error_rate': float(catastrophic_rate),
                    'confusion_matrix': [[int(cm[0, 0]), int(cm[0, 1])],
                                       [int(cm[1, 0]), int(cm[1, 1])]]
                })
                
                # ğŸ¯ æ–°å¢ï¼šæå–æ›´å¤šå…³é”®æŒ‡æ ‡
                if 'balanced_class_accuracy' in result_5min:
                    metrics['balanced_class_accuracy'] = float(result_5min['balanced_class_accuracy'])
                if 'composite_score' in result_5min:
                    metrics['composite_score'] = float(result_5min['composite_score'])
                if 'is_failed_model' in result_5min:
                    metrics['is_failed_model'] = bool(result_5min['is_failed_model'])
        
        return metrics
    
    def run_all_tests(self) -> pd.DataFrame:
        """è¿è¡Œæ‰€æœ‰æŸå¤±å‡½æ•°æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹æŸå¤±å‡½æ•°å¯¹æ¯”æµ‹è¯•")
        print(f"æµ‹è¯•è½®æ•°: {self.test_epochs}")
        print(f"å¼€å§‹æ—¶é—´: {self.start_time}")
        
        # å®šä¹‰æµ‹è¯•æ–¹æ¡ˆ - åªæµ‹è¯•binary_cross_entropyçš„ä¸åŒæƒé‡é…ç½®
        test_cases = [
            {
                'loss_type': 'binary_cross_entropy',
                'description': 'æ ‡å‡†äº¤å‰ç†µ-æƒé‡6.5',
                'weight_config': 6.5,
                'params': {}
            },
            {
                'loss_type': 'binary_cross_entropy', 
                'description': 'æ ‡å‡†äº¤å‰ç†µ-æƒé‡7.0',
                'weight_config': 7.0,
                'params': {}
            },
            {
                'loss_type': 'binary_cross_entropy',
                'description': 'æ ‡å‡†äº¤å‰ç†µ-æƒé‡7.5', 
                'weight_config': 7.5,
                'params': {}
            },
            {
                'loss_type': 'binary_cross_entropy',
                'description': 'æ ‡å‡†äº¤å‰ç†µ-æƒé‡8.0',
                'weight_config': 8.0,
                'params': {}
            },
            # {
            #     'loss_type': 'business_cost',
            #     'description': 'ä¸šåŠ¡æˆæœ¬é©±åŠ¨ï¼ˆè°ƒæ•´æ¼æŠ¥æˆæœ¬ï¼‰',
            #     'params': {
            #         'loss_function_params': {
            #             "business_cost": {
            #                 "false_alarm_cost": 1.0,    # è¯¯æŠ¥æˆæœ¬(ç¨³å®š->å˜åŒ–)
            #                 "miss_change_cost": 8.0,    # æ¼æŠ¥æˆæœ¬(å˜åŒ–->ç¨³å®š)
            #                 "correct_reward": 0.2,      # æ­£ç¡®é¢„æµ‹å¥–åŠ±
            #             }
            #         }
            #     }
            # },
        ]
        
        # æ‰§è¡Œæµ‹è¯•
        results = []
        total_tests = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ¯ è¿›åº¦: {i}/{total_tests}")
            print(f"ğŸ“ æµ‹è¯•é…ç½®: {test_case['description']}")
            
            try:
                # ä¼ å…¥weight_configå‚æ•°
                weight_config = test_case.get('weight_config', None)
                result = self.test_loss_function(
                    test_case['loss_type'], 
                    weight_config,
                    test_case['params']
                )
                
                # æ·»åŠ æè¿°ä¿¡æ¯åˆ°ç»“æœä¸­
                result['description'] = test_case['description']
                result['weight_config'] = weight_config
                results.append(result)
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        # ç”ŸæˆæŠ¥å‘Š
        return self._generate_report(results)
    
    def _generate_report(self, results: List[Dict]) -> pd.DataFrame:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ")
        print(f"{'='*60}")
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
        detail_file = f"outputs/loss_function_test_{timestamp}.json"
        with open(detail_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
        if len(df) > 0:
            report_file = f"outputs/loss_function_report_{timestamp}.csv"
            
            # é€‰æ‹©å…³é”®åˆ—
            key_columns = [
                'loss_function', 'status', 'accuracy', 'precision', 
                'recall', 'f1_score', 'stable_accuracy', 'change_accuracy',
                'false_positives', 'false_negatives', 'training_time'
            ]
            
            available_columns = [col for col in key_columns if col in df.columns]
            summary_df = df[available_columns].copy()
            
            # ä¿å­˜æŠ¥å‘Š
            summary_df.to_csv(report_file, index=False)
            print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {detail_file}")
            print(f"ğŸ“‹ ç®€åŒ–æŠ¥å‘Š: {report_file}")
            
            # æ‰“å°æ‘˜è¦
            self._print_summary(summary_df)
            
        return df
    
    def _print_summary(self, df: pd.DataFrame):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print(f"\nğŸ“ˆ æƒé‡é…ç½®å¯¹æ¯”æµ‹è¯•ç»“æœ:")
        print("="*80)
        
        successful_tests = df[df['status'] == 'success']
        
        if len(successful_tests) > 0:
            # ğŸ¯ ä¸ºæ¯ä¸ªæƒé‡é…ç½®å•ç‹¬è¾“å‡ºè¯¦ç»†ç»“æœ
            print("ğŸ“Š å„æƒé‡é…ç½®è¯¦ç»†ç»“æœ:")
            print("-"*80)
            
            for i, (_, row) in enumerate(successful_tests.iterrows(), 1):
                weight = row.get('weight_config', 'N/A')
                desc = row.get('description', row['loss_function'])
                
                print(f"\nğŸ”¸ é…ç½® {i}: {desc}")
                print(f"   æƒé‡è®¾ç½®: [1.0, {weight}]")
                
                # æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡
                stable_acc = row.get('stable_accuracy', 0)
                change_acc = row.get('change_accuracy', 0)
                f1 = row.get('f1_score', 0)
                accuracy = row.get('accuracy', 0)
                
                # çŠ¶æ€è¯„ä¼°
                if row.get('is_failed_model', False):
                    status = "âŒ å¤±è´¥"
                elif change_acc > 0.5 and stable_acc > 0.6:
                    status = "âœ… ä¼˜ç§€"
                elif change_acc > 0.3:
                    status = "âš ï¸  ä¸€èˆ¬"  
                else:
                    status = "ğŸ”´ è¾ƒå·®"
                
                print(f"   è¯„ä¼°çŠ¶æ€: {status}")
                print(f"   æ•´ä½“å‡†ç¡®ç‡: {accuracy:.3f}")
                print(f"   F1åˆ†æ•°: {f1:.3f}")
                print(f"   ç¨³å®šç±»å‡†ç¡®ç‡: {stable_acc:.3f}")
                print(f"   å˜åŒ–ç±»å‡†ç¡®ç‡: {change_acc:.3f}")
                
                # æ··æ·†çŸ©é˜µ
                cm = row.get('confusion_matrix', None)
                if cm:
                    print(f"   æ··æ·†çŸ©é˜µ:")
                    print(f"             é¢„æµ‹")
                    print(f"   å®é™…   ç¨³å®š(0)  å˜åŒ–(1)")
                    print(f"   ç¨³å®š(0)  {cm[0][0]:6d}   {cm[0][1]:6d}")
                    print(f"   å˜åŒ–(1)  {cm[1][0]:6d}   {cm[1][1]:6d}")
                
                # é”™è¯¯åˆ†æ
                fp = row.get('false_positives', 0)
                fn = row.get('false_negatives', 0) 
                catastrophic_rate = row.get('catastrophic_error_rate', 0)
                
                print(f"   è¯¯æŠ¥æ•°(ç¨³å®šâ†’å˜åŒ–): {fp}")
                print(f"   æ¼æŠ¥æ•°(å˜åŒ–â†’ç¨³å®š): {fn}")
                print(f"   ç¾éš¾é”™è¯¯ç‡: {catastrophic_rate:.3f}")
                
                # ç»¼åˆè¯„åˆ†
                if 'composite_score' in row:
                    print(f"   ç»¼åˆè¯„åˆ†: {row['composite_score']:.3f}")
                if 'balanced_class_accuracy' in row:
                    print(f"   å¹³è¡¡å‡†ç¡®ç‡: {row['balanced_class_accuracy']:.3f}")
                
                # æ¨¡å‹è·¯å¾„
                model_path = row.get('model_save_dir', 'N/A')
                print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
                print()
            
            # ğŸ¯ æƒé‡é…ç½®å¯¹æ¯”æ€»ç»“
            print("="*80)
            print("ğŸ“ˆ æƒé‡æ•ˆæœå¯¹æ¯”æ€»ç»“:")
            print("-"*50)
            
            # æŒ‰å˜åŒ–ç±»å‡†ç¡®ç‡æ’åº
            sorted_by_change = successful_tests.sort_values('change_accuracy', ascending=False)
            
            print("ğŸ¯ å˜åŒ–ç±»å‡†ç¡®ç‡æ’å:")
            for i, (_, row) in enumerate(sorted_by_change.iterrows(), 1):
                weight = row.get('weight_config', 'N/A')
                change_acc = row.get('change_accuracy', 0)
                stable_acc = row.get('stable_accuracy', 0)
                
                balance_indicator = "âš–ï¸ å¹³è¡¡" if abs(change_acc - stable_acc) < 0.3 else "âš ï¸ ä¸å¹³è¡¡"
                print(f"  {i}. æƒé‡[1.0, {weight}]: å˜åŒ–ç±»{change_acc:.3f} | ç¨³å®šç±»{stable_acc:.3f} {balance_indicator}")
            
            # æ•°å­¦æœŸæœ›åˆ†æ
            print(f"\nğŸ§® æ•°å­¦æœŸæœ›åˆ†æ (93.7%ç¨³å®šç±», 6.3%å˜åŒ–ç±»):")
            for _, row in successful_tests.iterrows():
                weight = row.get('weight_config', 'N/A')
                if weight != 'N/A':
                    expected_weight = 0.937 * 1.0 + 0.063 * weight
                    change_acc = row.get('change_accuracy', 0)
                    print(f"  æƒé‡[1.0, {weight}]: æœŸæœ›æƒé‡={expected_weight:.3f}, å®é™…å˜åŒ–ç±»å‡†ç¡®ç‡={change_acc:.3f}")
        
        # å¤±è´¥æµ‹è¯•
        failed_tests = df[df['status'] == 'failed']
        if len(failed_tests) > 0:
            print(f"\nâŒ è¿è¡Œå¤±è´¥çš„æµ‹è¯•:")
            for _, row in failed_tests.iterrows():
                print(f"  {row['loss_function']}: {row.get('error', 'Unknown error')}")

        # ğŸ¯ æ¨èç»“è®º
        if len(successful_tests) > 0:
            print(f"\nğŸ¯ æƒé‡è°ƒæ•´å»ºè®®:")
            
            # åˆ†ææƒé‡è¶‹åŠ¿
            weights_performance = []
            for _, row in successful_tests.iterrows():
                weight = row.get('weight_config', None)
                change_acc = row.get('change_accuracy', 0)
                if weight is not None:
                    weights_performance.append((weight, change_acc))
            
            if len(weights_performance) >= 2:
                weights_performance.sort()
                best_weight, best_change_acc = max(weights_performance, key=lambda x: x[1])
                
                print(f"  ğŸ“Š æœ€ä½³æƒé‡: [1.0, {best_weight}]")
                print(f"  ğŸ“ˆ æœ€ä½³å˜åŒ–ç±»å‡†ç¡®ç‡: {best_change_acc:.3f}")
                
                if best_change_acc < 0.3:
                    print(f"  ğŸ’¡ å»ºè®®: å˜åŒ–ç±»å‡†ç¡®ç‡ä»è¾ƒä½ï¼Œè€ƒè™‘:")
                    print(f"     - è¿›ä¸€æ­¥æå‡æƒé‡è‡³ [1.0, {best_weight + 2}] æˆ– [1.0, {best_weight + 5}]")
                    print(f"     - å°è¯•å…¶ä»–æŸå¤±å‡½æ•° (business_cost, focal_loss)")
                    print(f"     - è°ƒæ•´å­¦ä¹ ç‡æˆ–è®­ç»ƒç­–ç•¥")
                elif best_change_acc > 0.6:
                    print(f"  âœ… æƒé‡è°ƒæ•´æœ‰æ•ˆï¼å¯å°è¯•å¾®è°ƒè‡³ [1.0, {best_weight + 0.5}] ä¼˜åŒ–å¹³è¡¡æ€§")
                else:
                    print(f"  âš ï¸  æœ‰è¿›å±•ä½†ä»éœ€æ”¹è¿›ï¼Œå»ºè®®ç»§ç»­è°ƒæ•´æƒé‡")
            else:
                print("  âŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œæƒé‡è¶‹åŠ¿åˆ†æ")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æŸå¤±å‡½æ•°å¯¹æ¯”æµ‹è¯•')
    parser.add_argument('--epochs', type=int, default=3, 
                       help='æµ‹è¯•è½®æ•° (é»˜è®¤: 3)')
    parser.add_argument('--single', type=str, 
                       help='åªæµ‹è¯•å•ä¸ªæŸå¤±å‡½æ•°')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs('outputs', exist_ok=True)
    
    tester = LossFunctionTester(test_epochs=args.epochs)
    
    if args.single:
        # æµ‹è¯•å•ä¸ªæŸå¤±å‡½æ•°
        result = tester.test_loss_function(args.single)
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        for key, value in result.items():
            print(f"  {key}: {value}")
    else:
        # æµ‹è¯•æ‰€æœ‰æŸå¤±å‡½æ•°
        results_df = tester.run_all_tests()
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main() 